{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284ecd43-7880-40e6-988e-f7b057edc634",
   "metadata": {},
   "source": [
    "## Main idea\n",
    "\n",
    "Combine \n",
    "- fundamental,\n",
    "- technical (including weekly RSI, negatively divergent higher high/lower low), and\n",
    "- financial statements analysis\n",
    "\n",
    "to find stocks that are attractive to buy long term (as a buy and hold). Ideal holding period is 1 to 5 years.\n",
    "\n",
    "Goal is to hold these medium/long term and not worry so much about the allocation, then when the stocks look less attractive, then sell them (or a portion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f3c95d-a203-40d4-9c7d-d558070fd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from groq import Groq\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, Tuple, Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4384774-914d-46d1-8f99-c1db7a1cde36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('groq_api.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf25d3-ce52-4f75-8ffa-40c233e19343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Groq client\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "groq_client = Groq(api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073259f3-5eff-4f12-8de0-39957b89fbf2",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "\n",
    "### TODO\n",
    "Extend the function below to get all, or top 100 sp500 stocks, plus any that we currently own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a572bd-f074-4d84-b9ef-d7bc4327525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sp500_stocks(n=20):\n",
    "    # Declare top 10 stocks in S&P 500 (for demonstration)\n",
    "    tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'GOOG', 'META', 'TSLA', 'BRK.B', 'JPM', 'V', 'DASH', 'NFLX', 'DIS', 'SBUX', 'BABA', 'NVDA', 'BIDU', 'XOM', 'PEG', 'CEG', 'BWXT', 'NEM', 'GFI', 'HMY', 'CVX', 'AVGO', 'HD', 'PG', 'WMT', 'JNJ', 'ABBV']\n",
    "    \n",
    "    # Get market cap for each stock\n",
    "    market_caps = {}\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        market_caps[ticker] = stock.info.get('marketCap', 0)\n",
    "    \n",
    "    # Sort by market cap and get top n\n",
    "    top_stocks = sorted(market_caps.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    return [stock[0] for stock in top_stocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f7ae5-5619-4644-8cfa-01cba5978f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_stocks = get_top_sp500_stocks(6)\n",
    "pd.DataFrame(top_stocks, columns=['Ticker']).to_csv('top_20_stocks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a4568-ffb8-4453-9e05-aab18e18fb1f",
   "metadata": {},
   "source": [
    "## Retrieve financial data\n",
    "\n",
    "Retrieve both historical price data and income statements for each stock over the past five years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0743c90b-eb5c-4078-8b4d-10392477bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financial_data(ticker, start_date, end_date):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    \n",
    "    # Get historical price data\n",
    "    price_data = stock.history(start=start_date, end=end_date)\n",
    "    \n",
    "    # Get income statement\n",
    "    income_statement = stock.financials\n",
    "    \n",
    "    return {\n",
    "        \"price_data\": price_data,\n",
    "        \"income_statement\": income_statement\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8ff45-2188-48cc-9561-65b54a480bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.now() - timedelta(days=5*365)\n",
    "end_date = datetime.now()\n",
    "\n",
    "all_data = {}\n",
    "for ticker in top_stocks:\n",
    "    all_data[ticker] = get_financial_data(ticker, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ed9f6-5404-4342-93b2-15d1139e54f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17897b5f-5131-4404-9f20-6db7158f1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_income_statement_for_llm(income_statement_column):\n",
    "    formatted_text = \"\"\n",
    "    for index, value in income_statement_column.items():\n",
    "        formatted_value = f\"{value:,.2f}\" if isinstance(value, (int, float)) else str(value)\n",
    "        formatted_text += f\"{index}: {formatted_value}\\n\"\n",
    "    return formatted_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e14e77-c879-4c2f-a7f7-ffe0555bc99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "for ticker, data in all_data.items():\n",
    "    current_year = data['income_statement'].columns[0]\n",
    "    formatted_statement = format_income_statement_for_llm(data['income_statement'][current_year])\n",
    "    print(f\"Formatted Income Statement for {ticker}:\\n{formatted_statement}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff3af4-0662-435a-96fc-929071587595",
   "metadata": {},
   "source": [
    "## Prompt for income statement evaluation\n",
    "\n",
    "### TODO\n",
    "\n",
    "Update the prompt to figure out which financial metrics should be used out of the ones available in yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e8ef3-bcda-4f6a-be5f-9082aa32c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_for_income_statement_v0(current_year_income_statement, previous_year_income_statement):\n",
    "    prompt = f\"\"\"\n",
    "Evaluate the following income statements for the current year and the previous year. Provide a score between 0 and 10 for each criterion, where 0 is very poor and 10 is excellent. Consider criteria such as revenue growth, profitability, operating efficiency, and earnings quality. Additionally, provide an overall score based on the average of the criteria scores.\n",
    "\n",
    "Income Statement for the Current Year:\n",
    "{current_year_income_statement}\n",
    "\n",
    "Income Statement for the Previous Year:\n",
    "{previous_year_income_statement}\n",
    "\n",
    "Criteria for Evaluation:\n",
    "1. Revenue Growth: Analyze the growth in revenue compared to the previous year.\n",
    "2. Gross Profit Margin: Calculate as Gross Profit / Total Revenue.\n",
    "3. Operating Margin: Calculate as Operating Income / Total Revenue.\n",
    "4. Net Profit Margin: Calculate as Net Income / Total Revenue.\n",
    "5. EPS Growth: Compare EPS to the previous year.\n",
    "6. Operating Efficiency: Consider Operating Expense relative to Total Revenue.\n",
    "7. Interest Coverage Ratio: Calculate as EBIT / Interest Expense.\n",
    "\n",
    "Provide the score for each criterion and an overall score. Include explanations for each score.\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def create_prompt_for_income_statement_v1(current_year_income_statement, previous_year_income_statement):\n",
    "    prompt = f\"\"\"\n",
    "Evaluate the following income statements for the current year and the previous year. Provide a score between 0 and 10 for each criterion, where 0 is very poor and 10 is excellent. Consider criteria such as revenue growth, profitability, operating efficiency, and earnings quality. Additionally, provide an overall score based on the average of the criteria scores.\n",
    "\n",
    "Income Statement for the Current Year:\n",
    "{current_year_income_statement}\n",
    "\n",
    "Income Statement for the Previous Year:\n",
    "{previous_year_income_statement}\n",
    "\n",
    "Criteria for Evaluation:\n",
    "1. Revenue Growth: Analyze the growth in revenue compared to the previous year.\n",
    "2. Gross Profit Margin: Calculate as Gross Profit / Total Revenue.\n",
    "3. Operating Margin: Calculate as Operating Income / Total Revenue.\n",
    "4. Net Profit Margin: Calculate as Net Income / Total Revenue.\n",
    "5. EPS Growth: Analyze the growth in Earnings Per Share (EPS) compared to the previous year.\n",
    "6. Operating Efficiency: Consider Operating Expense relative to Total Revenue.\n",
    "7. Interest Coverage Ratio: Calculate as Earnings Before Interest and Taxes (EBIT) / Interest Expense.\n",
    "\n",
    "Example Format:\n",
    "1. Revenue Growth: 8.5\n",
    "2. Gross Profit Margin: 7.0\n",
    "3. Operating Margin: 6.5\n",
    "4. Net Profit Margin: 7.0\n",
    "5. EPS Growth: 8.0\n",
    "6. Operating Efficiency: 7.5\n",
    "7. Interest Coverage Ratio: 9.0\n",
    "Overall Score: 7.5\n",
    "\n",
    "Provide the score for each criterion and an overall score. Include explanations for each score.\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def create_prompt_for_income_statement(current_year_income_statement: Dict, previous_year_income_statement: Dict) -> str:\n",
    "    prompt = f\"\"\"\n",
    "Analyze the following income statements and provide a structured evaluation. Follow this EXACT format:\n",
    "\n",
    "CRITERION SCORES\n",
    "Revenue Growth: [score 0-10]\n",
    "REASON: [brief explanation]\n",
    "\n",
    "Gross Profit Margin: [score 0-10]\n",
    "REASON: [brief explanation]\n",
    "\n",
    "Operating Margin: [score 0-10]\n",
    "REASON: [brief explanation]\n",
    "\n",
    "Net Profit Margin: [score 0-10]\n",
    "REASON: [brief explanation]\n",
    "\n",
    "EPS Growth: [score 0-10]\n",
    "REASON: [brief explanation]\n",
    "\n",
    "Operating Efficiency: [score 0-10]\n",
    "REASON: [brief explanation]\n",
    "\n",
    "Interest Coverage: [score 0-10]\n",
    "REASON: [brief explanation]\n",
    "\n",
    "OVERALL SCORE: [average of above scores, rounded to 2 decimal places]\n",
    "\n",
    "SUMMARY: [brief overall analysis]\n",
    "\n",
    "Current Year Income Statement:\n",
    "{current_year_income_statement}\n",
    "\n",
    "Previous Year Income Statement:\n",
    "{previous_year_income_statement}\n",
    "\n",
    "Important:\n",
    "- Always provide numerical scores for ALL criteria\n",
    "- Scores must be between 0 and 10\n",
    "- If exact calculation isn't possible, estimate based on available data\n",
    "- Format must match the template exactly\n",
    "- Always include the OVERALL SCORE as a number\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e750592-2098-4b9d-9ab7-9036d6820fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_income_statements_llm_v0(current_year_income_statement, previous_year_income_statement):\n",
    "    prompt = create_prompt_for_income_statement(current_year_income_statement, previous_year_income_statement)\n",
    "    response = groq_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        temperature=0.2,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    analysis = response.choices[0].message.content.strip()\n",
    "    score = re.search(r\"Overall Score: (\\d+\\.\\d+)\", analysis)\n",
    "    return float(score.group(1)) if score else None\n",
    "\n",
    "def evaluate_income_statements_llm(current_year_income_statement: Dict, \n",
    "                                 previous_year_income_statement: Dict,\n",
    "                                 max_retries: int = 2) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Evaluate income statements with retry logic for failed parsing\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            prompt = create_prompt_for_income_statement(\n",
    "                current_year_income_statement, \n",
    "                previous_year_income_statement\n",
    "            )\n",
    "            \n",
    "            response = groq_client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                model=\"llama-3.1-8b-instant\",\n",
    "                temperature=0.2 - (attempt * 0.1),  # Reduce temperature on retries\n",
    "                max_tokens=1000\n",
    "            )\n",
    "            \n",
    "            result = process_llm_output(response.choices[0].message.content.strip())\n",
    "            \n",
    "            if result['overall_score'] is not None:\n",
    "                return result['overall_score']\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            \n",
    "        if attempt < max_retries - 1:\n",
    "            print(f\"Retrying evaluation... (Attempt {attempt + 2}/{max_retries})\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a189453-227b-468d-8787-25ede24b66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_output_v0(llm_output):\n",
    "    # Extract individual criterion scores\n",
    "    criterion_scores = re.findall(r\"(\\d+\\.\\s*[\\w\\s]+):\\s*(\\d+(?:\\.\\d+)?)\", llm_output)\n",
    "    \n",
    "    # Extract overall score\n",
    "    overall_score = re.search(r\"Overall Score: (\\d+(?:\\.\\d+)?)\", llm_output)\n",
    "    \n",
    "    return {\n",
    "        'criterion_scores': dict(criterion_scores),\n",
    "        'overall_score': float(overall_score.group(1)) if overall_score else None,\n",
    "        'full_analysis': llm_output\n",
    "    }\n",
    "\n",
    "def process_llm_output_v1(llm_output):\n",
    "    # Extract individual criterion scores\n",
    "    criterion_scores = re.findall(r\"(\\d+\\.\\s*[\\w\\s]+):\\s*(\\d+(?:\\.\\d+)?)\", llm_output)\n",
    "    \n",
    "    # Create a dictionary to store the scores\n",
    "    criterion_scores_dict = {score[0].strip(): float(score[1]) for score in criterion_scores}\n",
    "    \n",
    "    # Extract overall score\n",
    "    overall_score = re.search(r\"Overall Score:\\s*(\\d+(?:\\.\\d+)?)\", llm_output)\n",
    "    \n",
    "    return {\n",
    "        'criterion_scores': criterion_scores_dict,\n",
    "        'overall_score': float(overall_score.group(1)) if overall_score else None,\n",
    "        'full_analysis': llm_output\n",
    "    }\n",
    "\n",
    "def process_llm_output(llm_output: str) -> Dict[str, Any]:\n",
    "    # Define all expected criteria\n",
    "    expected_criteria = [\n",
    "        'Revenue Growth',\n",
    "        'Gross Profit Margin',\n",
    "        'Operating Margin',\n",
    "        'Net Profit Margin',\n",
    "        'EPS Growth',\n",
    "        'Operating Efficiency',\n",
    "        'Interest Coverage'\n",
    "    ]\n",
    "    \n",
    "    # Dictionary to store scores\n",
    "    scores = {}\n",
    "    \n",
    "    # Process each criterion\n",
    "    for criterion in expected_criteria:\n",
    "        # Look for scores in format \"Criterion: [score]\" or \"Criterion: score\"\n",
    "        pattern = rf\"{criterion}:\\s*(?:\\[)?(\\d+(?:\\.\\d+)?)(?:\\])?\"\n",
    "        match = re.search(pattern, llm_output)\n",
    "        if match:\n",
    "            scores[criterion] = float(match.group(1))\n",
    "    \n",
    "    # Extract overall score\n",
    "    overall_pattern = r\"OVERALL SCORE:\\s*(?:\\[)?(\\d+(?:\\.\\d+)?)(?:\\])?\"\n",
    "    overall_match = re.search(overall_pattern, llm_output)\n",
    "    overall_score = float(overall_match.group(1)) if overall_match else None\n",
    "    \n",
    "    # If we're missing any scores, calculate the overall score ourselves\n",
    "    if overall_score is None and scores:\n",
    "        overall_score = round(sum(scores.values()) / len(scores), 2)\n",
    "    \n",
    "    # Extract summary if present\n",
    "    summary_pattern = r\"SUMMARY:\\s*(.+?)(?=\\n|$)\"\n",
    "    summary_match = re.search(summary_pattern, llm_output)\n",
    "    summary = summary_match.group(1) if summary_match else \"\"\n",
    "    \n",
    "    return {\n",
    "        'criterion_scores': scores,\n",
    "        'overall_score': overall_score,\n",
    "        'summary': summary,\n",
    "        'full_analysis': llm_output\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91308fa-c7c5-4180-bbe0-ba4697abf117",
   "metadata": {},
   "source": [
    "## LLM stock evaluation\n",
    "\n",
    "### TODO \n",
    "\n",
    "Add technical analysis, any other components to create a composite score (e.g. using combined or weighted ranking) for the overall scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef54dd-ecaa-487c-bf49-eacdfbbe2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stock_v0(ticker, start_date, end_date):\n",
    "    data = get_financial_data(ticker, start_date, end_date)\n",
    "    income_statement = data['income_statement']\n",
    "    \n",
    "    scores = []\n",
    "    for i in range(len(income_statement.columns) - 1):\n",
    "        current_year = format_income_statement_for_llm(income_statement.iloc[:, i])\n",
    "        previous_year = format_income_statement_for_llm(income_statement.iloc[:, i+1])\n",
    "        score = evaluate_income_statements_llm(current_year, previous_year)\n",
    "        scores.append((income_statement.columns[i].year, score))\n",
    "    \n",
    "    return pd.DataFrame(scores, columns=['Year', 'Score'])\n",
    "\n",
    "def evaluate_stock(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate stock with improved error handling and logging\n",
    "    \"\"\"\n",
    "    data = get_financial_data(ticker, start_date, end_date)\n",
    "    income_statement = data['income_statement']\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(len(income_statement.columns) - 1):\n",
    "        try:\n",
    "            current_year = format_income_statement_for_llm(income_statement.iloc[:, i])\n",
    "            previous_year = format_income_statement_for_llm(income_statement.iloc[:, i+1])\n",
    "            \n",
    "            score = evaluate_income_statements_llm(current_year, previous_year)\n",
    "            \n",
    "            if score is not None:\n",
    "                scores.append({\n",
    "                    'Year': income_statement.columns[i].year,\n",
    "                    'Score': score\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Warning: Could not calculate score for {ticker} in {income_statement.columns[i].year}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ticker} for {income_statement.columns[i].year}: {str(e)}\")\n",
    "    \n",
    "    return pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372ccfe3-aab0-49e3-96b4-dd4452f3358a",
   "metadata": {},
   "source": [
    "Calculate scores for all of our stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02274002-7528-4df1-b375-a52fc426e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for ticker in top_stocks:\n",
    "    print(f\"Evaluating {ticker}...\")\n",
    "    scores = evaluate_stock(ticker, start_date, end_date)\n",
    "    scores['Ticker'] = ticker\n",
    "    all_scores.append(scores)\n",
    "\n",
    "all_scores = pd.concat(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ef3f0-6ef5-4539-8254-d1d5134ed48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae10d90-8ff7-4c5f-9541-fe3abce66ffb",
   "metadata": {},
   "source": [
    "## Visualizing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56302f-f429-4407-b2e5-a12aff79329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table\n",
    "pivoted_scores = all_scores.pivot(index='Year', columns='Ticker', values='Score')\n",
    "\n",
    "# Sort the index (Year) in descending order to have the most recent year first\n",
    "pivoted_scores = pivoted_scores.sort_index(ascending=False)\n",
    "\n",
    "# Keep only the last 3 years\n",
    "pivoted_scores = pivoted_scores.head(3)\n",
    "\n",
    "# Reset the index to make 'Year' a regular column\n",
    "pivoted_scores = pivoted_scores.reset_index()\n",
    "\n",
    "# Save the pivoted DataFrame to a CSV file\n",
    "pivoted_scores.to_csv('pivoted_stock_scores.csv', index=False)\n",
    "\n",
    "print(pivoted_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a50a024-ecea-45e3-bdd4-fbdb1c4581af",
   "metadata": {},
   "source": [
    "## Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a40ce-ec24-4c4e-a337-9e687a189bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fce6079-70a3-4feb-92d0-4f0a6ad8f283",
   "metadata": {},
   "source": [
    "# Fundamental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc2348-ffcc-477c-96c9-9d4df89009f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, List, Optional\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from yahooquery import Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2dec13-c4c9-41ab-b1e9-4927316f4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FundamentalAnalyzer:\n",
    "    def __init__(self, ticker: str):\n",
    "        self.ticker = ticker\n",
    "        self.yf_ticker = yf.Ticker(ticker)\n",
    "        self.yq_ticker = Ticker(ticker)\n",
    "        \n",
    "    def get_all_financial_data(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive financial data from multiple sources\"\"\"\n",
    "        try:\n",
    "            return {\n",
    "                'income_statement': self.yf_ticker.financials,\n",
    "                'balance_sheet': self.yf_ticker.balance_sheet,\n",
    "                'cash_flow': self.yf_ticker.cashflow,\n",
    "                'info': self.yf_ticker.info,\n",
    "                'institutional_holders': self.yf_ticker.institutional_holders,\n",
    "                'recommendations': self.yf_ticker.recommendations,\n",
    "                'sustainability': self.yf_ticker.sustainability,\n",
    "                'calendar': self.yf_ticker.calendar\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching financial data: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def calculate_financial_ratios(self, data: Dict[str, pd.DataFrame]) -> Dict[str, float]:\n",
    "        \"\"\"Calculate key financial ratios\"\"\"\n",
    "        try:\n",
    "            latest_income = data['income_statement'].iloc[:, 0]  # Most recent year\n",
    "            latest_balance = data['balance_sheet'].iloc[:, 0]\n",
    "            latest_cash_flow = data['cash_flow'].iloc[:, 0]\n",
    "            \n",
    "            ratios = {\n",
    "                # Profitability Ratios\n",
    "                'gross_margin': (latest_income['Gross Profit'] / latest_income['Total Revenue']) * 100,\n",
    "                'operating_margin': (latest_income['Operating Income'] / latest_income['Total Revenue']) * 100,\n",
    "                'net_margin': (latest_income['Net Income'] / latest_income['Total Revenue']) * 100,\n",
    "                'roe': (latest_income['Net Income'] / latest_balance['Total Stockholder Equity']) * 100,\n",
    "                \n",
    "                # Liquidity Ratios\n",
    "                'current_ratio': latest_balance['Total Current Assets'] / latest_balance['Total Current Liabilities'],\n",
    "                'quick_ratio': (latest_balance['Total Current Assets'] - latest_balance['Inventory']) / \n",
    "                              latest_balance['Total Current Liabilities'],\n",
    "                \n",
    "                # Efficiency Ratios\n",
    "                'asset_turnover': latest_income['Total Revenue'] / latest_balance['Total Assets'],\n",
    "                'inventory_turnover': latest_income['Total Revenue'] / latest_balance.get('Inventory', 1),\n",
    "                \n",
    "                # Leverage Ratios\n",
    "                'debt_to_equity': latest_balance['Total Liabilities'] / latest_balance['Total Stockholder Equity'],\n",
    "                'debt_to_assets': latest_balance['Total Liabilities'] / latest_balance['Total Assets'],\n",
    "                \n",
    "                # Cash Flow Ratios\n",
    "                'operating_cash_flow_ratio': latest_cash_flow['Operating Cash Flow'] / latest_balance['Total Current Liabilities'],\n",
    "                'cash_flow_coverage': latest_cash_flow['Operating Cash Flow'] / latest_balance['Total Liabilities']\n",
    "            }\n",
    "            \n",
    "            return {k: round(float(v), 2) for k, v in ratios.items() if not pd.isna(v)}\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating ratios: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def get_market_data(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get market-related data\"\"\"\n",
    "        try:\n",
    "            info = self.yf_ticker.info\n",
    "            return {\n",
    "                'market_cap': info.get('marketCap'),\n",
    "                'enterprise_value': info.get('enterpriseValue'),\n",
    "                'pe_ratio': info.get('trailingPE'),\n",
    "                'forward_pe': info.get('forwardPE'),\n",
    "                'price_to_book': info.get('priceToBook'),\n",
    "                'enterprise_to_ebitda': info.get('enterpriseToEbitda'),\n",
    "                'beta': info.get('beta'),\n",
    "                'dividend_yield': info.get('dividendYield', 0) * 100,\n",
    "                'fifty_two_week_high': info.get('fiftyTwoWeekHigh'),\n",
    "                'fifty_two_week_low': info.get('fiftyTwoWeekLow')\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching market data: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def get_peer_comparison(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Get peer comparison data\"\"\"\n",
    "        try:\n",
    "            # Get peers from Yahoo Finance\n",
    "            peers = self.yq_ticker.get_peer_companies()\n",
    "            if not isinstance(peers, list):\n",
    "                return {}\n",
    "            \n",
    "            peer_data = {}\n",
    "            for peer in peers[:5]:  # Limit to 5 peers for efficiency\n",
    "                peer_ticker = yf.Ticker(peer)\n",
    "                peer_data[peer] = {\n",
    "                    'Market Cap': peer_ticker.info.get('marketCap'),\n",
    "                    'P/E Ratio': peer_ticker.info.get('trailingPE'),\n",
    "                    'Revenue Growth': peer_ticker.info.get('revenueGrowth'),\n",
    "                    'Profit Margin': peer_ticker.info.get('profitMargin'),\n",
    "                    'ROE': peer_ticker.info.get('returnOnEquity')\n",
    "                }\n",
    "            \n",
    "            return {'peer_comparison': pd.DataFrame(peer_data).T}\n",
    "        except Exception as e:\n",
    "            print(f\"Error in peer comparison: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def analyze_trend(self, data: pd.DataFrame, periods: int = 4) -> Dict[str, float]:\n",
    "        \"\"\"Analyze trends in financial metrics\"\"\"\n",
    "        try:\n",
    "            trends = {}\n",
    "            for column in data.columns:\n",
    "                values = data[column].values[:periods]\n",
    "                if len(values) >= 2:\n",
    "                    trend = np.polyfit(range(len(values)), values, 1)[0]\n",
    "                    trends[f'{column}_trend'] = trend\n",
    "            return trends\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing trends: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def get_comprehensive_analysis(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive fundamental analysis\"\"\"\n",
    "        # Get all financial data\n",
    "        financial_data = self.get_all_financial_data()\n",
    "        if not financial_data:\n",
    "            return {'error': 'Failed to fetch financial data'}\n",
    "\n",
    "        # Calculate all components\n",
    "        analysis = {\n",
    "            'financial_ratios': self.calculate_financial_ratios(financial_data),\n",
    "            'market_data': self.get_market_data(),\n",
    "            'peer_comparison': self.get_peer_comparison(),\n",
    "            'financial_trends': {\n",
    "                'income_trends': self.analyze_trend(financial_data['income_statement']),\n",
    "                'balance_trends': self.analyze_trend(financial_data['balance_sheet']),\n",
    "                'cash_flow_trends': self.analyze_trend(financial_data['cash_flow'])\n",
    "            },\n",
    "            'esg_data': self.yf_ticker.sustainability,\n",
    "            'raw_financial_data': financial_data\n",
    "        }\n",
    "\n",
    "        return analysis\n",
    "\n",
    "def format_analysis_report(analysis: Dict[str, Any]) -> str:\n",
    "    \"\"\"Format the analysis results into a readable report\"\"\"\n",
    "    report = []\n",
    "    \n",
    "    # Financial Health Score (simple version)\n",
    "    def calculate_health_score(ratios: Dict[str, float]) -> float:\n",
    "        if not ratios:\n",
    "            return 0\n",
    "        \n",
    "        weights = {\n",
    "            'current_ratio': 0.15,\n",
    "            'debt_to_equity': 0.15,\n",
    "            'operating_margin': 0.2,\n",
    "            'roe': 0.2,\n",
    "            'net_margin': 0.15,\n",
    "            'asset_turnover': 0.15\n",
    "        }\n",
    "        \n",
    "        score = 0\n",
    "        for metric, weight in weights.items():\n",
    "            if metric in ratios:\n",
    "                # Normalize the ratio and add to score\n",
    "                if metric in ['current_ratio', 'roe', 'operating_margin', 'net_margin', 'asset_turnover']:\n",
    "                    score += min(max(ratios[metric], 0), 10) * weight\n",
    "                else:  # For metrics where lower is better\n",
    "                    score += (10 - min(max(ratios[metric], 0), 10)) * weight\n",
    "        \n",
    "        return round(score, 2)\n",
    "\n",
    "    # Add sections to report\n",
    "    if 'financial_ratios' in analysis:\n",
    "        report.append(\"Financial Health Score: \" + \n",
    "                     str(calculate_health_score(analysis['financial_ratios'])) + \" / 10\")\n",
    "        \n",
    "        report.append(\"\\nKey Financial Ratios:\")\n",
    "        for ratio, value in analysis['financial_ratios'].items():\n",
    "            report.append(f\"{ratio.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "    if 'market_data' in analysis:\n",
    "        report.append(\"\\nMarket Metrics:\")\n",
    "        for metric, value in analysis['market_data'].items():\n",
    "            if value is not None:\n",
    "                if 'market_cap' in metric or 'enterprise_value' in metric:\n",
    "                    value = f\"${value:,.0f}\"\n",
    "                elif isinstance(value, float):\n",
    "                    value = f\"{value:.2f}\"\n",
    "                report.append(f\"{metric.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "    if 'peer_comparison' in analysis and 'peer_comparison' in analysis['peer_comparison']:\n",
    "        report.append(\"\\nPeer Comparison Summary:\")\n",
    "        peer_df = analysis['peer_comparison']['peer_comparison']\n",
    "        report.append(str(peer_df.describe()))\n",
    "\n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "# Example usage:\n",
    "def analyze_stock(ticker: str) -> str:\n",
    "    analyzer = FundamentalAnalyzer(ticker)\n",
    "    analysis = analyzer.get_comprehensive_analysis()\n",
    "    return format_analysis_report(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee40cf3-5ceb-46d1-8674-3887798da320",
   "metadata": {},
   "source": [
    "# Technical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d413d-20b0-46be-8091-d1f604669655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b089aa-a906-4b2b-a971-d32e9d552ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TechnicalSignal:\n",
    "    date: pd.Timestamp\n",
    "    signal_type: str\n",
    "    strength: float\n",
    "    reason: str\n",
    "\n",
    "class TechnicalAnalyzer:\n",
    "    def __init__(self, ticker: str, period: str = \"2y\", interval: str = \"1wk\"):\n",
    "        \"\"\"\n",
    "        Initialize with default parameters for technical analysis\n",
    "        period: valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "        interval: valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "        \"\"\"\n",
    "        self.ticker = ticker\n",
    "        self.data = self._get_price_data(ticker, period, interval)\n",
    "        \n",
    "    def _get_price_data(self, ticker: str, period: str, interval: str) -> pd.DataFrame:\n",
    "        \"\"\"Fetch and prepare price data\"\"\"\n",
    "        stock = yf.Ticker(ticker)\n",
    "        df = stock.history(period=period, interval=interval)\n",
    "        return df\n",
    "    \n",
    "    def calculate_rsi(self, window: int = 14) -> pd.Series:\n",
    "        \"\"\"Calculate Relative Strength Index\"\"\"\n",
    "        delta = self.data['Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rs = gain / loss\n",
    "        return 100 - (100 / (1 + rs))\n",
    "    \n",
    "    def calculate_macd(self, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[pd.Series, pd.Series, pd.Series]:\n",
    "        \"\"\"Calculate MACD, Signal line, and MACD histogram\"\"\"\n",
    "        exp1 = self.data['Close'].ewm(span=fast, adjust=False).mean()\n",
    "        exp2 = self.data['Close'].ewm(span=slow, adjust=False).mean()\n",
    "        macd = exp1 - exp2\n",
    "        signal_line = macd.ewm(span=signal, adjust=False).mean()\n",
    "        histogram = macd - signal_line\n",
    "        return macd, signal_line, histogram\n",
    "    \n",
    "    def calculate_moving_averages(self) -> Dict[str, pd.Series]:\n",
    "        \"\"\"Calculate various moving averages\"\"\"\n",
    "        return {\n",
    "            'SMA20': self.data['Close'].rolling(window=20).mean(),\n",
    "            'SMA50': self.data['Close'].rolling(window=50).mean(),\n",
    "            'SMA200': self.data['Close'].rolling(window=200).mean(),\n",
    "            'EMA20': self.data['Close'].ewm(span=20, adjust=False).mean(),\n",
    "            'EMA50': self.data['Close'].ewm(span=50, adjust=False).mean()\n",
    "        }\n",
    "    \n",
    "    def detect_divergence_v0(self, price: pd.Series, indicator: pd.Series, window: int = 20) -> List[TechnicalSignal]:\n",
    "        \"\"\"\n",
    "        Detect regular and hidden divergence patterns\n",
    "        Returns list of divergence signals\n",
    "        \"\"\"\n",
    "        signals = []\n",
    "        \n",
    "        # Get local maxima and minima\n",
    "        def get_extrema(series: pd.Series, window: int) -> Tuple[pd.Series, pd.Series]:\n",
    "            maxima = pd.Series(index=series.index, dtype=float)\n",
    "            minima = pd.Series(index=series.index, dtype=float)\n",
    "            \n",
    "            for i in range(window, len(series) - window):\n",
    "                if all(series.iloc[i] > series.iloc[i-window:i]) and \\\n",
    "                   all(series.iloc[i] > series.iloc[i+1:i+window+1]):\n",
    "                    maxima.iloc[i] = series.iloc[i]\n",
    "                if all(series.iloc[i] < series.iloc[i-window:i]) and \\\n",
    "                   all(series.iloc[i] < series.iloc[i+1:i+window+1]):\n",
    "                    minima.iloc[i] = series.iloc[i]\n",
    "                    \n",
    "            return maxima.dropna(), minima.dropna()\n",
    "        \n",
    "        price_maxima, price_minima = get_extrema(price, window)\n",
    "        ind_maxima, ind_minima = get_extrema(indicator, window)\n",
    "        \n",
    "        # Detect bearish regular divergence (higher highs in price, lower highs in indicator)\n",
    "        for i in range(1, len(price_maxima)):\n",
    "            if price_maxima.iloc[i] > price_maxima.iloc[i-1] and \\\n",
    "               ind_maxima.iloc[i] < ind_maxima.iloc[i-1]:\n",
    "                signals.append(TechnicalSignal(\n",
    "                    date=price_maxima.index[i],\n",
    "                    signal_type='bearish_divergence',\n",
    "                    strength=0.8,\n",
    "                    reason='Bearish regular divergence: Higher price high with lower indicator high'\n",
    "                ))\n",
    "        \n",
    "        # Detect bullish regular divergence (lower lows in price, higher lows in indicator)\n",
    "        for i in range(1, len(price_minima)):\n",
    "            if price_minima.iloc[i] < price_minima.iloc[i-1] and \\\n",
    "               ind_minima.iloc[i] > ind_minima.iloc[i-1]:\n",
    "                signals.append(TechnicalSignal(\n",
    "                    date=price_minima.index[i],\n",
    "                    signal_type='bullish_divergence',\n",
    "                    strength=0.8,\n",
    "                    reason='Bullish regular divergence: Lower price low with higher indicator low'\n",
    "                ))\n",
    "                \n",
    "        return signals\n",
    "\n",
    "    def detect_divergence(self, price: pd.Series, indicator: pd.Series, window: int = 20) -> List[TechnicalSignal]:\n",
    "        signals = []\n",
    "        \n",
    "        # Get local maxima and minima\n",
    "        def get_extrema(series: pd.Series, window: int) -> Tuple[pd.Series, pd.Series]:\n",
    "            maxima = pd.Series(index=series.index, dtype=float)\n",
    "            minima = pd.Series(index=series.index, dtype=float)\n",
    "            \n",
    "            for i in range(window, len(series) - window):\n",
    "                if all(series.iloc[i] > series.iloc[i-window:i]) and \\\n",
    "                   all(series.iloc[i] > series.iloc[i+1:i+window+1]):\n",
    "                    maxima.iloc[i] = series.iloc[i]\n",
    "                if all(series.iloc[i] < series.iloc[i-window:i]) and \\\n",
    "                   all(series.iloc[i] < series.iloc[i+1:i+window+1]):\n",
    "                    minima.iloc[i] = series.iloc[i]\n",
    "                    \n",
    "            return maxima.dropna(), minima.dropna()\n",
    "        \n",
    "        price_maxima, price_minima = get_extrema(price, window)\n",
    "        ind_maxima, ind_minima = get_extrema(indicator, window)\n",
    "        \n",
    "        # Debugging: Print lengths\n",
    "        print(f\"Length of price_minima: {len(price_minima)}\")\n",
    "        print(f\"Length of ind_minima: {len(ind_minima)}\")\n",
    "        \n",
    "        # Reindex ind_minima to match price_minima\n",
    "        ind_minima = ind_minima.reindex(price_minima.index, fill_value=np.nan)\n",
    "        \n",
    "        # Detect bearish regular divergence (higher highs in price, lower highs in indicator)\n",
    "        for i in range(1, len(price_maxima)):\n",
    "            if pd.isna(ind_maxima.iloc[i]) or pd.isna(ind_maxima.iloc[i-1]):\n",
    "                continue\n",
    "            if price_maxima.iloc[i] > price_maxima.iloc[i-1] and \\\n",
    "               ind_maxima.iloc[i] < ind_maxima.iloc[i-1]:\n",
    "                signals.append(TechnicalSignal(\n",
    "                    date=price_maxima.index[i],\n",
    "                    signal_type='bearish_divergence',\n",
    "                    strength=0.8,\n",
    "                    reason='Bearish regular divergence: Higher price high with lower indicator high'\n",
    "                ))\n",
    "        \n",
    "        # Detect bullish regular divergence (lower lows in price, higher lows in indicator)\n",
    "        for i in range(1, len(price_minima)):\n",
    "            if pd.isna(ind_minima.iloc[i]) or pd.isna(ind_minima.iloc[i-1]):\n",
    "                continue\n",
    "            if price_minima.iloc[i] < price_minima.iloc[i-1] and \\\n",
    "               ind_minima.iloc[i] > ind_minima.iloc[i-1]:\n",
    "                signals.append(TechnicalSignal(\n",
    "                    date=price_minima.index[i],\n",
    "                    signal_type='bullish_divergence',\n",
    "                    strength=0.8,\n",
    "                    reason='Bullish regular divergence: Lower price low with higher indicator low'\n",
    "                ))\n",
    "                \n",
    "        return signals\n",
    "    \n",
    "    def calculate_volume_profile(self, bins: int = 50) -> pd.DataFrame:\n",
    "        \"\"\"Calculate volume profile for price levels\"\"\"\n",
    "        price_bins = pd.cut(self.data['Close'], bins=bins)\n",
    "        return self.data['Volume'].groupby(price_bins).sum().sort_index()\n",
    "    \n",
    "    def detect_support_resistance(self, window: int = 20, threshold: float = 0.1) -> Tuple[List[float], List[float]]:\n",
    "        \"\"\"Detect support and resistance levels using price action and volume\"\"\"\n",
    "        volume_profile = self.calculate_volume_profile()\n",
    "        high_volume_levels = volume_profile[volume_profile > volume_profile.quantile(1 - threshold)].index\n",
    "        \n",
    "        support_levels = []\n",
    "        resistance_levels = []\n",
    "        \n",
    "        for level in high_volume_levels:\n",
    "            price_level = level.mid\n",
    "            # Check if price has reversed near this level multiple times\n",
    "            touches = sum((self.data['Low'] <= price_level * 1.01) & \n",
    "                         (self.data['Low'] >= price_level * 0.99))\n",
    "            if touches >= 3:\n",
    "                support_levels.append(price_level)\n",
    "                \n",
    "            touches = sum((self.data['High'] <= price_level * 1.01) & \n",
    "                         (self.data['High'] >= price_level * 0.99))\n",
    "            if touches >= 3:\n",
    "                resistance_levels.append(price_level)\n",
    "                \n",
    "        return support_levels, resistance_levels\n",
    "    \n",
    "    def analyze_price_action(self) -> Dict[str, Any]:\n",
    "        \"\"\"Perform comprehensive price action analysis\"\"\"\n",
    "        # Calculate indicators\n",
    "        rsi = self.calculate_rsi()\n",
    "        macd, signal, histogram = self.calculate_macd()\n",
    "        mas = self.calculate_moving_averages()\n",
    "        \n",
    "        # Detect divergences\n",
    "        rsi_divergences = self.detect_divergence(self.data['Close'], rsi)\n",
    "        macd_divergences = self.detect_divergence(self.data['Close'], macd)\n",
    "        \n",
    "        # Get support/resistance levels\n",
    "        support, resistance = self.detect_support_resistance()\n",
    "        \n",
    "        # Generate signals based on multiple indicators\n",
    "        signals = []\n",
    "        \n",
    "        # Check for oversold/overbought conditions with confirmation\n",
    "        for i in range(len(self.data)):\n",
    "            if i < 2:\n",
    "                continue\n",
    "                \n",
    "            # Oversold conditions (potential buy)\n",
    "            if (rsi.iloc[i] < 30 and  # RSI oversold\n",
    "                histogram.iloc[i] > histogram.iloc[i-1] and  # MACD histogram turning up\n",
    "                self.data['Close'].iloc[i] > mas['SMA20'].iloc[i]):  # Price above short-term MA\n",
    "                \n",
    "                signals.append(TechnicalSignal(\n",
    "                    date=self.data.index[i],\n",
    "                    signal_type='buy',\n",
    "                    strength=0.7,\n",
    "                    reason='Oversold conditions with positive momentum'\n",
    "                ))\n",
    "                \n",
    "            # Overbought conditions (potential sell)\n",
    "            if (rsi.iloc[i] > 70 and  # RSI overbought\n",
    "                histogram.iloc[i] < histogram.iloc[i-1] and  # MACD histogram turning down\n",
    "                self.data['Close'].iloc[i] < mas['SMA20'].iloc[i]):  # Price below short-term MA\n",
    "                \n",
    "                signals.append(TechnicalSignal(\n",
    "                    date=self.data.index[i],\n",
    "                    signal_type='sell',\n",
    "                    strength=0.7,\n",
    "                    reason='Overbought conditions with negative momentum'\n",
    "                ))\n",
    "        \n",
    "        return {\n",
    "            'indicators': {\n",
    "                'rsi': rsi,\n",
    "                'macd': macd,\n",
    "                'macd_signal': signal,\n",
    "                'macd_histogram': histogram,\n",
    "                'moving_averages': mas\n",
    "            },\n",
    "            'signals': signals + rsi_divergences + macd_divergences,\n",
    "            'levels': {\n",
    "                'support': support,\n",
    "                'resistance': resistance\n",
    "            }\n",
    "        }\n",
    "\n",
    "def generate_analysis_report(ticker: str) -> str:\n",
    "    \"\"\"Generate a readable technical analysis report\"\"\"\n",
    "    analyzer = TechnicalAnalyzer(ticker)\n",
    "    analysis = analyzer.analyze_price_action()\n",
    "    \n",
    "    report = [f\"Technical Analysis Report for {ticker}\\n\"]\n",
    "    \n",
    "    # Add current indicator values\n",
    "    current_rsi = analysis['indicators']['rsi'].iloc[-1]\n",
    "    current_macd = analysis['indicators']['macd'].iloc[-1]\n",
    "    report.append(f\"Current RSI: {current_rsi:.2f}\")\n",
    "    report.append(f\"Current MACD: {current_macd:.2f}\")\n",
    "    \n",
    "    # Add recent signals\n",
    "    recent_signals = [s for s in analysis['signals'] \n",
    "                     if s.date >= analyzer.data.index[-10]]  # Last 10 periods\n",
    "    \n",
    "    if recent_signals:\n",
    "        report.append(\"\\nRecent Signals:\")\n",
    "        for signal in recent_signals:\n",
    "            report.append(f\"{signal.date.date()}: {signal.signal_type} \"\n",
    "                        f\"(Strength: {signal.strength:.1f})\")\n",
    "            report.append(f\"Reason: {signal.reason}\")\n",
    "    \n",
    "    # Add support/resistance levels\n",
    "    report.append(\"\\nKey Price Levels:\")\n",
    "    report.append(f\"Support levels: {', '.join(f'${x:.2f}' for x in analysis['levels']['support'])}\")\n",
    "    report.append(f\"Resistance levels: {', '.join(f'${x:.2f}' for x in analysis['levels']['resistance'])}\")\n",
    "    \n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "# Example usage:\n",
    "# report = generate_analysis_report('AAPL')\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6888b-10ab-447a-9af9-6c0a3ac18ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = generate_analysis_report('AAPL')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4be28-526c-4924-a25f-7adf1cf13474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
